---
title: 机器学习笔记
tags: 数学，计算机
categories: 学习笔记
date: 2019-05-04 17:42:17
---

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" async
  src="https://wujilingfeng.top/MathJax/MathJax.js?config=TeX-AMS_CHTML">
</script>


本文记录机器学习笔记

<!--more-->

##### 信息熵

获取这里用”编码量“更”严谨“，假设一个事件的概率是$p_i$,则它的编码量是$-logp_i$,log以2为底。那么对于概率测度$\left(\Omega,A,\mu\right)$,其平均一次编码量为$H\left(p\right)=-E\left(log\mu\left(A\right)\right)$

###### 命题

$-E\left(log\mu\left(A\right)\right)=\sum p_ilog\frac{1}{p_i}\leq log\sum 1$等号成立的条件是$p_i$全相等

##### 相对熵

$KL\left(P,Q\right)=\sum p_ilog\frac{p_i}{q_i}$

易知$P=Q$时取最小值（证明方法同上）

有人用KL散度（编码量差）度量概率空间，这是不合理的。事实上概率空间可以用全变差来度量，和wassertein距离度量。

如果非要用到信息熵。我们可以对概率测度P做这样的变换$\frac{1}{H\left(p\right)}p_ilogp_i  $这是新的概率测度，我们可以衡量新生城的概率测度。

在向往的生活3中陈伟霆玩的游戏中我们了解到监督学习(博弈类学习)的困难。

#### 神经元（工程）

神经元适合模拟事物规律，所以神经元适合"学习"分类，识别问题。

